{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 [0.93 0.87 0.96 0.97 0.93 0.93 0.94 0.9  0.98 0.86]\n",
      "8 [0.93 0.87 0.96 0.97 0.93 0.93 0.94 0.9  0.97 0.86]\n",
      "8 [0.93 0.87 0.96 0.97 0.93 0.93 0.94 0.9  0.97 0.86]\n",
      "8 [0.93 0.87 0.96 0.97 0.93 0.93 0.94 0.9  0.98 0.86]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%reload_ext autoreload\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "def sigmoid(t):\n",
    "    \"\"\"a step function made continous in order to use calculus (differential)\"\"\"\n",
    "    return 1 / (1 + math.exp(-t)) # t=0 -> 1/2, t=100 -> ~ 1, t=-100 -> ~0\n",
    "\n",
    "def neuron_output(weights, inputs):\n",
    "    \"\"\"reduces all values from input array and weights array to a value between 0 to 1\"\"\"\n",
    "    return sigmoid(dot(weights, inputs)) \n",
    "\n",
    "def dot(v, w):\n",
    "    \"\"\"v_1 * w_1 + ... + v_n * w_n\"\"\"\n",
    "    return sum(v_i * w_i for v_i, w_i in zip(v, w))\n",
    "\n",
    "random.seed(0)   # to get repeatable results\n",
    "input_size = 25  # each input is a vector of length 25 (5x5 \"pixels\")\n",
    "\n",
    "num_hidden = 5   # we'll have 5 neurons in the hidden layer\n",
    "output_size = 10 # we need 10 outputs for each input\n",
    "\n",
    "# each hidden neuron has one weight per input, plus a bias weight\n",
    "hidden_layer = [[random.random() for _ in range(input_size + 1)]\n",
    "                 for _ in range(num_hidden)]\n",
    "#print(hidden_layer)\n",
    "\n",
    "# each output neuron has one weight per hidden neuron, plus a bias weight\n",
    "output_layer = [[random.random() for _ in range(num_hidden + 1)]\n",
    "                 for _ in range(output_size)]\n",
    "#print(output_layer)\n",
    "\n",
    "# the network starts out with random weights, one hidden layer and one output layer\n",
    "network = [hidden_layer, output_layer]\n",
    "\n",
    "def feed_forward(neural_network, input_vector):\n",
    "    \"\"\"takes in a neural network\n",
    "    (represented as a list of lists(non-input layers) of lists(neurons) of weights)\n",
    "    and returns the output from forward-propagating the input\"\"\"\n",
    "    outputs = []\n",
    "    # process one layer at a time\n",
    "    for layer in neural_network:\n",
    "        input_with_bias = input_vector + [1]               # add a bias input\n",
    "        output = [neuron_output(neuron, input_with_bias)   # compute the output\n",
    "            for neuron in layer]                           # for each neuron\n",
    "        outputs.append(output)                             # and remember it\n",
    "        \n",
    "        # then the input to the next layer is the output of this one\n",
    "        input_vector = output\n",
    "    return outputs\n",
    "\n",
    "\n",
    "our_dataset = [\n",
    "        \"\"\"@@@@@\n",
    "        @...@\n",
    "        @..@@\n",
    "        @...@\n",
    "        @@@@@\"\"\",\n",
    "        \"\"\".@@@@\n",
    "        ....@\n",
    "        @@.@@\n",
    "        @....\n",
    "        @@@@@\"\"\",\n",
    "        \"\"\"@.@.@\n",
    "        @...@\n",
    "        @@@@@\n",
    "        ....@\n",
    "        ....@\"\"\",\n",
    "        \"\"\"@@@@@\n",
    "        @....\n",
    "        @@.@@\n",
    "        @...@\n",
    "        @@@@@\"\"\"]\n",
    "\n",
    "def make_digit(raw_digit):\n",
    "    \"\"\"transform digit set to using zeros instead of dots\"\"\"\n",
    "    return [1 if c == '@' else 0\n",
    "            for row in raw_digit.split(\"\\n\")\n",
    "            for c in row.strip()]\n",
    "\n",
    "\n",
    "our_inputs = [make_digit(raw_digit) for raw_digit in our_dataset]\n",
    "\n",
    "def predict(in_put):\n",
    "    return feed_forward(network, in_put)[-1]\n",
    "\n",
    "def plot_testset(data):\n",
    "    count = 0\n",
    "    f = plt.figure(figsize=(10, 5))\n",
    "    data = np.array(data)\n",
    "    for idx, row in enumerate(data):\n",
    "        imarray = row.reshape((5, 5))\n",
    "        plt.subplot(2, len(data), idx + 1)\n",
    "        plt.subplots_adjust(hspace=0.5)\n",
    "        count += 1\n",
    "        plt.imshow(imarray, cmap='Greys', interpolation='None')\n",
    "    return plt\n",
    "\n",
    "\n",
    "test_set = [[0,1,1,1,0,\n",
    "             0,0,0,1,1,\n",
    "             0,0,1,1,0,\n",
    "             0,0,0,1,1,\n",
    "             0,1,1,1,0],\n",
    "            [0,1,1,1,0,\n",
    "             1,0,0,1,1,\n",
    "             0,1,1,1,0,\n",
    "             1,0,0,1,1,\n",
    "             0,1,1,1,0],\n",
    "            [0,0,1,0,0,\n",
    "             0,0,1,0,0,\n",
    "             0,0,1,0,0,\n",
    "             0,0,1,0,0,\n",
    "             0,0,1,0,0],\n",
    "            [0,1,1,0,0,\n",
    "             0,0,1,0,0,\n",
    "             0,0,1,0,0,\n",
    "             0,0,1,0,0,\n",
    "             0,0,1,0,0]]\n",
    "#print(test_set)\n",
    "#plt.show(plot_testset(test_set))\n",
    "\n",
    "for test_data in our_inputs:\n",
    "    result = predict(test_data)\n",
    "    result = np.array(result)\n",
    "    print(np.argmax(result), np.array_str(result, precision=2, suppress_small=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_digits = [\n",
    "        \"\"\"@@@@@\n",
    "           @...@\n",
    "           @...@\n",
    "           @...@\n",
    "           @@@@@\"\"\",\n",
    "        \"\"\"..@..\n",
    "           ..@..\n",
    "           ..@..\n",
    "           ..@..\n",
    "           ..@..\"\"\",\n",
    "        \"\"\"@@@@@\n",
    "           ....@\n",
    "           @@@@@\n",
    "           @....\n",
    "           @@@@@\"\"\",\n",
    "        \"\"\"@@@@@\n",
    "           ....@\n",
    "           @@@@@\n",
    "           ....@\n",
    "           @@@@@\"\"\",\n",
    "        \"\"\"@...@\n",
    "           @...@\n",
    "           @@@@@\n",
    "           ....@\n",
    "           ....@\"\"\",\n",
    "        \"\"\"@@@@@\n",
    "           @....\n",
    "           @@@@@\n",
    "           ....@\n",
    "           @@@@@\"\"\",\n",
    "        \"\"\"@@@@@\n",
    "           @....\n",
    "           @@@@@\n",
    "           @...@\n",
    "           @@@@@\"\"\",\n",
    "        \"\"\"@@@@@\n",
    "           ....@\n",
    "           ....@\n",
    "           ....@\n",
    "           ....@\"\"\",\n",
    "        \"\"\"@@@@@\n",
    "           @...@\n",
    "           @@@@@\n",
    "           @...@\n",
    "           @@@@@\"\"\",\n",
    "        \"\"\"@@@@@\n",
    "           @...@\n",
    "           @@@@@\n",
    "           ....@\n",
    "           @@@@@\"\"\"]\n",
    "\n",
    "\n",
    "def make_digit(raw_digit):\n",
    "    \"\"\"transform digit set to using zeros instead of dots\"\"\"\n",
    "    return [1 if c == '@' else 0\n",
    "            for row in raw_digit.split(\"\\n\")\n",
    "            for c in row.strip()]\n",
    "\n",
    "\n",
    "inputs = [make_digit(raw_digit) for raw_digit in raw_digits]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
